---
title: "Data Manipulation"
output:
  pdf_document: default
  html_document: default
---

Load necessary packages.

```{r, include=FALSE}
library(tidyverse)
```

And let's read some data that we'll be working with.

```{r}
crew <- read_csv("https://raw.githubusercontent.com/unolibraries/workshops/master/data-manipulation-r/crewlists.csv")
```

## Mutate

Before we can start, we have to do some data cleanup. Take a look at the structure of the data. 

```{r}
str(crew)
```

You'll notice a few problems right off the bat. **ApproximateDeparture**, for example, is a character rather than a number. Let's fix that first. 

The `mutate()` function lets us create new columns out of existing columns. Below, we split out the ApproximateDeparture data, replace the long-form date with just the year using some regex (we're not covering this today, but don't worry if you don't understand it -- part of writing code is being comfortable with what you don't understand at first.) Then, once we have a new `year` column, we recombine that data with our existing data frame using `mutate()`. 

```{r}
departure <- crew %>% pull(ApproximateDeparture) %>% 
  str_replace(".*([0-9]{4}).*", "\\1") %>% 
  as.numeric()
# We've created a large numeric list of departure years, now we want to recombine
# that data with our data frame.

crew_tidied <- crew %>%
  mutate(year = departure)
```

Now we can inspect our data again, and see that there's a new column called `year` classed as a numeric column (`num`). 

```{r}
str(crew_tidied)
```

# Select

We can select which columns we want by putting the name of the column in the `select()` function. Here we pick three columns.

```{r}
crew_tidied %>% 
  select(FullName, Rig, Age)
```

We can also get rid of columns by using the `-` sign. The `starts_with()` and `ends_with()` functions are useful.

Read the documentation for this function, `?select`.

Select the three `name` columns by looking for the columns that end with `Name`.

```{r}

```

Remove the column `Remarks`.

```{r}

```

Pick just the columns that you want:

```{r}

```

# Filter

Filtering is more interesting. To keep certain rows, we have to pass the `filter()` function a vector of `TRUE` and `FALSE` values, one for each row. The most common way to do that is to use a comparison operator on a column of the data.

```{r}
crew_tidied %>% 
  filter(Rig == "Bark")
```

```{r}
crew_tidied %>% 
  filter(Age > 18) 
```

Can you get just the Sloop rig and those over 18 years old? (Hint: you can string together filters with comma separations.)

```{r}

```

Can you get just the ships that sailed between 1820 and 1870?

```{r}

```

Get just the rows from 1890.

```{r}

```

# Arrange

The `arrange()` function lets us sort. Often we want to sort a data frame by one of its columns. This can be done with the verb `arrange()`. By default `arrange()` will sort from least to greatest; we can use the function `desc()` to sort from greatest to least. In this example, we sort the data frame to get the ships that sailed in 1830 sorted by age. (Notice that we can create a pipeline of functions.)

```{r}
crew_tidied %>% 
  filter(year == 1830) %>% 
  arrange(desc(Age))
```

## Data reshaping (`spread()` and `gather()`)

It can be helpful to think of tabular data as coming in two forms: wide data, and long data. Let's load two sets of sample data to get a sense of how these work.

```{r}
population <- read.csv("https://raw.githubusercontent.com/unolibraries/workshops/master/data-manipulation-r/population.csv")
population

cases <- read.csv("https://raw.githubusercontent.com/unolibraries/workshops/master/data-manipulation-r/cases.csv")
cases
```

The first thing we can notice about this data frame is that it is very wide because it has a column for each of the countries. The data is also suitable for reading because it reads like a table in a publication. We can read from left to right and see population or case values for each year. The difficulties of computing on or plotting the data will also become quickly apparent. How would you make a plot of the change over time? Or how would you filter by year, or summarize by year? For that matter, what do the numbers in the table represent, since they are not given an explicit variable name?

The problem with the table is that it is not *tidy data*, because the variables are not in columns and observations in rows. One of the variables is the year, but its values are in the column headers. And another of the variables is population, but its values are spread across rows and columns and it is not explicitly named. 

The `gather()` function from the [tidyr](https://cran.rstudio.com/web/packages/tidyr/) package lets us turn wide data into long data. We need to tell the function two kinds of information. First we need to tell it the name of the column to create from the column headers and the name of the implicit variable in the rows. In the example below, we create two new columns `year` and `cases`. Then we also have to tell the function if there are any columns which should remain unchanged. If that were the case, we would remove it from the gathering using the same syntax as the `select()` function.

```{r}
population %>% 
  # we want the last two columns, so we tell R to select the range of columns from 2-3
  gather(year, population, 2:3) 
```

We can see the results above.

The inverse operation of `gather()` is `spread()`. With `spread()` we specify the name of the column which should become the new column headers (in this case `cases` and `population`), and then the name of the column to fill in underneath those new column headers (in this case, `key` and `value`). We can see the results below.

```{r}
cases %>% 
  spread(key, value)
```

Just by looking at the data we can see that we got back to where we started, but we can also verify that programmatically using the `identical()` function.

Turning long data into wide is often useful when you want to create a tabular representation of data. (And once you have a data frame that can be a table, the `knitr::kable()` function is quite nice.) And some algorithms, such as clustering algorithms, expect wide data rather than tidy data.

# Group by and summarize

We're going to switch data gears and work with another set of data: Census information for every US city between 1790 and 2010. Let's start by reading in that data: 

```{r}
cities <- read_csv("https://raw.githubusercontent.com/unolibraries/workshops/master/data-manipulation-r/CESTACityData.csv")
```

Is the data tidy? (Hint: no. Make a new data frame called `tidied` using `gather`.)

```{r}

```

Notice that in the example above the `arrange()` function sorted the entire data frame. So when we looked for the counties with the largest number of people, we got rows from 2000, then 1990, then 1980, then 1970, and so on. What if we wanted to get the biggest county from each year?

We can solve this kind of problem with what Hadley Wickham calls the "split-apply-combine" pattern of data analysis. Think of it this way. First we can *split* the big data frame into separate data frames, one for each year. Then we can *apply* our logic to get the results we want; in this case, that means sorting the data frame. We might also want to get just the top one row with the biggest number of people. Then we can *combine* those split apart data frames into a new data frame.

Observe how this works. If we want to get the county with the most people per year, we can use the following code:

```{r}
tidied %>% 
  select(ST, year, County, population) %>% 
  group_by(year) %>% 
  arrange(desc(population)) %>% 
  slice(1) 
```

Let's walk through that logic step by step. 

1. First, we select only the columns that we are interested in, namely, the column for the year, the total population, the county, and the year. We do this just so that the results print out in a useful way: in a real analysis we might decide not to throw away the other columns.
2. The crucial step is when we `group_by()` the `year`. This creates a new data-frame (the *split* step) for each unique combination of values in the variables. (Note that you can group by combinations of columns, so, one group for each combination of city and state, for instance.)
4. Next we *apply* our logic, in this case, sorting by the column `population` in descending order. This puts the rows with the biggest value at the top.
5. Next we continue to *apply* our logic with `slice()`. This function simply gives us the rows in each of the split-up data frames with that index. So `slice(1)` gives us the first row, `slice(5)` gives us this fifth row, and `slice(1:5)` gives us the first through fifth rows. 
6. The last step, *combine*, where the split-up data frames are brought back together, is done for us automatically. Note that the data frame is still grouped, however, so any subsequent data manipulation verbs will be applied to the groups rather than the whole data frame. If we wished, we could use `ungroup()`.

This particular operation, getting the top value in a split up data frame is so common that dplyr provides us with a `top_n()` function as a short cut. That function also handles ties better. (What if, for instance, two counties both have the same biggest value?)

```{r}
tidied %>% 
  select(ST, County, year, population) %>% 
  group_by(year) %>% 
  top_n(1, population)
```

We get the same results more concisely and reliably, though the steps of "split-apply-combine" are perhaps somewhat less easy to see.

## Summarizing or aggregating data (`summarize()`)

In the examples using `top_n()` or `slice()` we performed a very simple kind of data summary, where we took the single row with the biggest value in a given column. This essentially boiled many rows of a data frame down into a single row. We would like to be able to summarize or aggregate a data frame in other ways as well. For instance, we often want to take the sum or the mean of a given column. We can do this using the `summarize()` function in conjunction with the `group_by()` function.

The data that we are currently working with has one row for each combination of a **year** and a **population**. We might want to know the total number of people for each year. To do this, we need to group by a variable, then use an aggregation function.

```{r}
tidied %>% 
  group_by(year) %>% 
  summarize(totalPopulation = sum(population))
```

Notice that we get one row in the recombined data frame for each group in the original data frame. The value in the new column is the result of a function (in this case, `sum()`) applied to the columns in each of the split apart data frames.

There is also a special case where we might want to know how many rows were in each of the split apart (or grouped) data frames. We can use the special `n()` function to get that count. (Just like the case of `slice()` and `top_n()`, this is such a common thing to do that dplyr provides the special functions `count()` and `tally()`. You can look up their documentation to see how they work.)

```{r}
tidied %>% 
  group_by(ST) %>% 
  summarize(total_counties = n())
```

For each year, what were the top three largest counties?

```{r}

```

# Capstone

For the year 1910, what was the largest county in each state?

```{r}

```

For each year, what were the three largest counties in Nebraska?

```{r}

```

How would you arrange the population of all counties by largest first? 

```{r}

```
